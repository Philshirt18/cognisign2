{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9a8jT0ehDMmJzJkQvSPzc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Philshirt18/cognisign2/blob/main/notebooks/Cognisight_AI_Speech_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cognisight — Reproducible Notebook\n",
        "\n",
        "This notebook clones the repo, installs dependencies, loads or synthesizes demo audio, extracts features, trains a calibrated baseline, evaluates (ROC-AUC, PPV@0.80 sensitivity, ECE), and runs a demo inference. Not a diagnosis; demo only.\n"
      ],
      "metadata": {
        "id": "1fc198QBk7Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RESET WORKING DIR\n",
        "%cd /content\n",
        "\n",
        "# CLONE YOUR REPO FRESH\n",
        "REPO_URL = \"https://github.com/Philshirt18/cognisign2.git\"\n",
        "PROJECT_DIR = \"/content/cognisight\"\n",
        "\n",
        "!rm -rf \"$PROJECT_DIR\"\n",
        "!git clone \"$REPO_URL\" \"$PROJECT_DIR\"\n",
        "!ls -la \"$PROJECT_DIR\" | head -n 50\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmBqKWsWgCs9",
        "outputId": "eb683312-64bf-4dd9-916c-6331c4250bf0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/content/cognisight'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 84 (delta 23), reused 73 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (84/84), 4.19 MiB | 26.49 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "total 252\n",
            "drwxr-xr-x 6 root root   4096 Nov  4 13:54 .\n",
            "drwxr-xr-x 1 root root   4096 Nov  4 13:54 ..\n",
            "-rw-r--r-- 1 root root  15328 Nov  4 13:54 Cognisight.ipynb\n",
            "-rw-r--r-- 1 root root     99 Nov  4 13:54 .eslintrc.json\n",
            "drwxr-xr-x 8 root root   4096 Nov  4 13:54 .git\n",
            "-rw-r--r-- 1 root root     90 Nov  4 13:54 .gitignore\n",
            "-rw-r--r-- 1 root root    164 Nov  4 13:54 next.config.js\n",
            "-rw-r--r-- 1 root root    201 Nov  4 13:54 next-env.d.ts\n",
            "drwxr-xr-x 2 root root   4096 Nov  4 13:54 notebooks\n",
            "-rw-r--r-- 1 root root    525 Nov  4 13:54 package.json\n",
            "-rw-r--r-- 1 root root 186106 Nov  4 13:54 package-lock.json\n",
            "drwxr-xr-x 3 root root   4096 Nov  4 13:54 public\n",
            "-rw-r--r-- 1 root root   1967 Nov  4 13:54 README.md\n",
            "drwxr-xr-x 5 root root   4096 Nov  4 13:54 src\n",
            "-rw-r--r-- 1 root root    756 Nov  4 13:54 tsconfig.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $PROJECT_DIR\n",
        "\n",
        "# If requirements.txt exists, install; otherwise continue\n",
        "!if [ -f requirements.txt ]; then pip -q install -r requirements.txt; else echo \"No requirements.txt found — continuing.\"; fi\n",
        "\n",
        "# Core libs you need for the rest of the notebook\n",
        "!pip -q install librosa scikit-learn soundfile numpy pandas matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3uV_bUgFy5",
        "outputId": "a0f94819-6295-4268-bd76-fee633caa082"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cognisight\n",
            "No requirements.txt found — continuing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, pathlib\n",
        "sys.path.append(str(pathlib.Path.cwd()))\n",
        "!ls -R | head -n 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcI8ORcfglpK",
        "outputId": "0918049d-3f3d-480b-e8fd-885fbae454d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "Cognisight.ipynb\n",
            "next.config.js\n",
            "next-env.d.ts\n",
            "notebooks\n",
            "package.json\n",
            "package-lock.json\n",
            "public\n",
            "README.md\n",
            "src\n",
            "tsconfig.json\n",
            "\n",
            "./notebooks:\n",
            "Cognisight_AI_Speech_Analysis.ipynb\n",
            "\n",
            "./public:\n",
            "demo\n",
            "\n",
            "./public/demo:\n",
            "healthy.wav\n",
            "higher-risk.wav\n",
            "README.txt\n",
            "\n",
            "./src:\n",
            "app\n",
            "components\n",
            "lib\n",
            "types.ts\n",
            "\n",
            "./src/app:\n",
            "api\n",
            "disclaimer\n",
            "globals.css\n",
            "layout.tsx\n",
            "page.tsx\n",
            "\n",
            "./src/app/api:\n",
            "process-audio\n",
            "\n",
            "./src/app/api/process-audio:\n",
            "route.ts\n",
            "\n",
            "./src/app/disclaimer:\n",
            "page.tsx\n",
            "\n",
            "./src/components:\n",
            "AnalysisSummary.tsx\n",
            "AudioPreview.tsx\n",
            "FileUploader.tsx\n",
            "Hero.tsx\n",
            "OnboardingSteps.tsx\n",
            "Recorder.tsx\n",
            "\n",
            "./src/lib:\n",
            "api.ts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "AUDIO_DIR = os.path.join(PROJECT_DIR, \"sample_audio\")\n",
        "files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))\n",
        "print(\"Found audio files:\", files[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7lKA04vgpAx",
        "outputId": "90fc437f-04fb-4e67-c1dd-d28150e9c8b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found audio files: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(files) == 0:\n",
        "    import numpy as np, soundfile as sf\n",
        "    AUDIO_DIR = \"/content/demo_audio\"; os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "    sr = 16000\n",
        "    def tone(freq, secs, noise=0.01, amp=0.2):\n",
        "        t = np.linspace(0, secs, int(sr*secs), endpoint=False)\n",
        "        x = (np.sin(2*np.pi*freq*t)*amp).astype(\"float32\")\n",
        "        x += np.random.normal(0, noise, x.shape).astype(\"float32\")\n",
        "        return x\n",
        "    for i in range(6):\n",
        "        x = np.concatenate([tone(220,0.6), tone(220,0.6), tone(220,0.6)], 0)\n",
        "        sf.write(f\"{AUDIO_DIR}/ctrl_{i}.wav\", x, sr)\n",
        "    for i in range(6):\n",
        "        x = np.concatenate([tone(220,0.3,amp=0.08), tone(320,0.3), tone(220,0.3,amp=0.08), tone(320,0.3)], 0)\n",
        "        sf.write(f\"{AUDIO_DIR}/imp_{i}.wav\", x, sr)\n",
        "    files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))\n",
        "print(\"Using audio files:\", files[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNeys6e5g3CL",
        "outputId": "2921848e-155d-4915-b9fa-db01ce70d6c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using audio files: ['/content/demo_audio/imp_0.wav', '/content/demo_audio/ctrl_3.wav', '/content/demo_audio/imp_5.wav', '/content/demo_audio/ctrl_0.wav', '/content/demo_audio/imp_2.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from app.audio.features import extract_features  # adjust if your repo path differs\n",
        "except Exception as e:\n",
        "    print(\"Fallback to minimal MFCC extractor:\", e)\n",
        "    import librosa, numpy as np\n",
        "    def extract_features(path):\n",
        "        y, sr = librosa.load(path, sr=16000)\n",
        "        if len(y) < sr:\n",
        "            y = librosa.util.fix_length(y, size=sr)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        return np.concatenate([mfcc.mean(axis=1), mfcc.std(axis=1)], axis=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oAaD07qkdIc",
        "outputId": "7392c1f1-f2ce-4b75-f32c-6d4e033db995"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fallback to minimal MFCC extractor: No module named 'app'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, os\n",
        "X, y = [], []\n",
        "for f in files:\n",
        "    X.append(extract_features(f))\n",
        "    y.append(1 if os.path.basename(f).startswith(\"imp_\") else 0)\n",
        "X = np.vstack(X)\n",
        "y = np.array(y)\n",
        "X.shape, y.shape, y.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PijnbiF-kgCB",
        "outputId": "2d2c19e2-0be5-498c-da10-a5762e0764ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 26), (12,), np.float64(0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_auc_score, recall_score, precision_score\n",
        "import numpy as np\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "base = make_pipeline(StandardScaler(), LogisticRegression(max_iter=200, class_weight=\"balanced\"))\n",
        "cal = CalibratedClassifierCV(base, method=\"isotonic\", cv=3)\n",
        "cal.fit(Xtr, ytr)\n",
        "\n",
        "probs = cal.predict_proba(Xte)[:, 1]\n",
        "auc = roc_auc_score(yte, probs)\n",
        "\n",
        "# PPV at 0.80 sensitivity\n",
        "thresholds = np.linspace(0, 1, 1001)\n",
        "best_ppv = 0.0\n",
        "chosen = 0.5\n",
        "for t in thresholds:\n",
        "    preds = (probs >= t).astype(int)\n",
        "    sens = recall_score(yte, preds)\n",
        "    if sens >= 0.80:\n",
        "        ppv = precision_score(yte, preds, zero_division=0)\n",
        "        if ppv > best_ppv:\n",
        "            best_ppv, chosen = ppv, t\n",
        "\n",
        "# Simple ECE (10 bins)\n",
        "bins = np.linspace(0, 1, 11)\n",
        "ece = 0.0\n",
        "for i in range(len(bins) - 1):\n",
        "    lo, hi = bins[i], bins[i + 1]\n",
        "    idx = (probs >= lo) & (probs < hi)\n",
        "    if idx.sum() == 0:\n",
        "        continue\n",
        "    conf = probs[idx].mean()\n",
        "    acc = ((probs[idx] >= chosen).astype(int) == yte[idx]).mean()\n",
        "    ece += idx.mean() * abs(acc - conf)\n",
        "\n",
        "print(f\"ROC-AUC: {auc:.2f}\")\n",
        "print(f\"PPV @ 0.80 sensitivity: {best_ppv:.2f} (threshold ~ {chosen:.2f})\")\n",
        "print(f\"ECE: {ece:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhR8ATBSkjfP",
        "outputId": "93ad7222-8242-4fae-d4c1-a69868fc2a15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 1.00\n",
            "PPV @ 0.80 sensitivity: 1.00 (threshold ~ 0.02)\n",
            "ECE: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = files[0]\n",
        "feat = extract_features(test_path).reshape(1, -1)\n",
        "p = cal.predict_proba(feat)[0, 1]\n",
        "print(\"Test file:\", os.path.basename(test_path))\n",
        "print(f\"Estimated risk score: {p:.2f}\")\n",
        "print(\"Not a diagnosis — demo only.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_-ety7jkn_A",
        "outputId": "f217f8c8-9d37-487a-820a-28e4e595a598"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test file: imp_0.wav\n",
            "Estimated risk score: 0.99\n",
            "Not a diagnosis — demo only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, sklearn, librosa, numpy\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"librosa:\", librosa.__version__)\n",
        "print(\"numpy:\", numpy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJMZwH23krrd",
        "outputId": "34b72bfb-4686-4c53-ca2b-a090c4c6ac90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "sklearn: 1.6.1\n",
            "librosa: 0.11.0\n",
            "numpy: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File → Save a copy to GitHub  \n",
        "Repo: select my repo  \n",
        "Path: /notebooks/Cognisight_AI_Speech_Analysis.ipynb  \n",
        "Commit: “Add reproducible hackathon notebook”\n"
      ],
      "metadata": {
        "id": "OPXYfrr9kvWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Colab](https://colab.research.google.com/assets/colab-badge.svg)\n"
      ],
      "metadata": {
        "id": "vj6FcC_jk1EL"
      }
    }
  ]
}