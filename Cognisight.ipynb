{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkz4MX5cOsg/gOXd1NT+Kr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Philshirt18/cognisign2/blob/main/Cognisight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cognisight — Reproducible Notebook\n",
        "\n",
        "This notebook clones the repo, installs dependencies, loads or synthesizes demo audio, extracts features, trains a calibrated baseline, evaluates (ROC-AUC, PPV@0.80 sensitivity, ECE), and runs a demo inference. Not a diagnosis; demo only.\n"
      ],
      "metadata": {
        "id": "1fc198QBk7Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_URL = \"https://github.com/Philshirt18/cognisign2.git\"\n",
        "PROJECT_DIR = \"/content/cognisight\"\n",
        "import os, shutil\n",
        "shutil.rmtree(PROJECT_DIR, ignore_errors=True)\n",
        "!git clone $REPO_URL $PROJECT_DIR\n",
        "!ls -la $PROJECT_DIR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmBqKWsWgCs9",
        "outputId": "7a242fd3-e27d-46d7-c39b-a63662eb3233"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/cognisight'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 77 (delta 20), reused 74 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 4.19 MiB | 9.14 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "total 232\n",
            "drwxr-xr-x 5 root root   4096 Nov  4 11:31 .\n",
            "drwxr-xr-x 1 root root   4096 Nov  4 11:31 ..\n",
            "-rw-r--r-- 1 root root     99 Nov  4 11:31 .eslintrc.json\n",
            "drwxr-xr-x 8 root root   4096 Nov  4 11:31 .git\n",
            "-rw-r--r-- 1 root root     90 Nov  4 11:31 .gitignore\n",
            "-rw-r--r-- 1 root root    164 Nov  4 11:31 next.config.js\n",
            "-rw-r--r-- 1 root root    201 Nov  4 11:31 next-env.d.ts\n",
            "-rw-r--r-- 1 root root    525 Nov  4 11:31 package.json\n",
            "-rw-r--r-- 1 root root 186106 Nov  4 11:31 package-lock.json\n",
            "drwxr-xr-x 3 root root   4096 Nov  4 11:31 public\n",
            "-rw-r--r-- 1 root root   1967 Nov  4 11:31 README.md\n",
            "drwxr-xr-x 5 root root   4096 Nov  4 11:31 src\n",
            "-rw-r--r-- 1 root root    756 Nov  4 11:31 tsconfig.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $PROJECT_DIR\n",
        "!pip -q install -r requirements.txt || print(\"No requirements.txt or some deps failed; proceeding with core libs.\")\n",
        "!pip -q install librosa scikit-learn soundfile numpy pandas matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3uV_bUgFy5",
        "outputId": "7af03d87-2b6c-40b0-a8b9-785e2076bf89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cognisight\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `\"No requirements.txt or some deps failed; proceeding with core libs.\"'\n",
            "/bin/bash: -c: line 1: `pip -q install -r requirements.txt || print(\"No requirements.txt or some deps failed; proceeding with core libs.\")'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, pathlib\n",
        "sys.path.append(str(pathlib.Path.cwd()))\n",
        "!ls -R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcI8ORcfglpK",
        "outputId": "2dae59d1-f57b-4ae9-d4da-3f2afefdad1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "next.config.js\tpackage.json\t   public     src\n",
            "next-env.d.ts\tpackage-lock.json  README.md  tsconfig.json\n",
            "\n",
            "./public:\n",
            "demo\n",
            "\n",
            "./public/demo:\n",
            "healthy.wav  higher-risk.wav  README.txt\n",
            "\n",
            "./src:\n",
            "app  components  lib  types.ts\n",
            "\n",
            "./src/app:\n",
            "api  disclaimer  globals.css  layout.tsx  page.tsx\n",
            "\n",
            "./src/app/api:\n",
            "process-audio\n",
            "\n",
            "./src/app/api/process-audio:\n",
            "route.ts\n",
            "\n",
            "./src/app/disclaimer:\n",
            "page.tsx\n",
            "\n",
            "./src/components:\n",
            "AnalysisSummary.tsx  FileUploader.tsx  OnboardingSteps.tsx\n",
            "AudioPreview.tsx     Hero.tsx\t       Recorder.tsx\n",
            "\n",
            "./src/lib:\n",
            "api.ts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "AUDIO_DIR = os.path.join(PROJECT_DIR, \"sample_audio\")\n",
        "files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))\n",
        "print(\"Found audio files:\", files[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7lKA04vgpAx",
        "outputId": "4872c17e-81f9-4490-dd57-2ac7cc582038"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found audio files: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(files) == 0:\n",
        "    import numpy as np, soundfile as sf, os\n",
        "    AUDIO_DIR = \"/content/demo_audio\"\n",
        "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "    sr = 16000\n",
        "    def tone(freq, secs, noise=0.01, amp=0.2):\n",
        "        t = np.linspace(0, secs, int(sr * secs), endpoint=False)\n",
        "        x = (np.sin(2 * np.pi * freq * t) * amp).astype(\"float32\")\n",
        "        x += np.random.normal(0, noise, x.shape).astype(\"float32\")\n",
        "        return x\n",
        "    for i in range(6):\n",
        "        x = np.concatenate([tone(220, 0.6), tone(220, 0.6), tone(220, 0.6)], axis=0)\n",
        "        sf.write(f\"{AUDIO_DIR}/ctrl_{i}.wav\", x, sr)\n",
        "    for i in range(6):\n",
        "        x = np.concatenate([tone(220, 0.3, amp=0.08), tone(320, 0.3), tone(220, 0.3, amp=0.08), tone(320, 0.3)], axis=0)\n",
        "        sf.write(f\"{AUDIO_DIR}/imp_{i}.wav\", x, sr)\n",
        "    files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))\n",
        "print(\"Using audio files:\", files[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNeys6e5g3CL",
        "outputId": "852bd5c0-a375-4f91-84f2-8f5165127108"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using audio files: ['/content/demo_audio/imp_0.wav', '/content/demo_audio/ctrl_3.wav', '/content/demo_audio/imp_5.wav', '/content/demo_audio/ctrl_0.wav', '/content/demo_audio/imp_2.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from app.audio.features import extract_features  # adjust if your repo path differs\n",
        "except Exception as e:\n",
        "    print(\"Fallback to minimal MFCC extractor:\", e)\n",
        "    import librosa, numpy as np\n",
        "    def extract_features(path):\n",
        "        y, sr = librosa.load(path, sr=16000)\n",
        "        if len(y) < sr:\n",
        "            y = librosa.util.fix_length(y, size=sr)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        return np.concatenate([mfcc.mean(axis=1), mfcc.std(axis=1)], axis=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oAaD07qkdIc",
        "outputId": "b8c6ebb8-6ea1-4540-988c-ee4b8aa1ec71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fallback to minimal MFCC extractor: No module named 'app'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, os\n",
        "X, y = [], []\n",
        "for f in files:\n",
        "    X.append(extract_features(f))\n",
        "    y.append(1 if os.path.basename(f).startswith(\"imp_\") else 0)\n",
        "X = np.vstack(X)\n",
        "y = np.array(y)\n",
        "X.shape, y.shape, y.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PijnbiF-kgCB",
        "outputId": "a59e9b82-75de-42a4-fea1-efe9af3d1d67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 26), (12,), np.float64(0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_auc_score, recall_score, precision_score\n",
        "import numpy as np\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "base = make_pipeline(StandardScaler(), LogisticRegression(max_iter=200, class_weight=\"balanced\"))\n",
        "cal = CalibratedClassifierCV(base, method=\"isotonic\", cv=3)\n",
        "cal.fit(Xtr, ytr)\n",
        "\n",
        "probs = cal.predict_proba(Xte)[:, 1]\n",
        "auc = roc_auc_score(yte, probs)\n",
        "\n",
        "# PPV at 0.80 sensitivity\n",
        "thresholds = np.linspace(0, 1, 1001)\n",
        "best_ppv = 0.0\n",
        "chosen = 0.5\n",
        "for t in thresholds:\n",
        "    preds = (probs >= t).astype(int)\n",
        "    sens = recall_score(yte, preds)\n",
        "    if sens >= 0.80:\n",
        "        ppv = precision_score(yte, preds, zero_division=0)\n",
        "        if ppv > best_ppv:\n",
        "            best_ppv, chosen = ppv, t\n",
        "\n",
        "# Simple ECE (10 bins)\n",
        "bins = np.linspace(0, 1, 11)\n",
        "ece = 0.0\n",
        "for i in range(len(bins) - 1):\n",
        "    lo, hi = bins[i], bins[i + 1]\n",
        "    idx = (probs >= lo) & (probs < hi)\n",
        "    if idx.sum() == 0:\n",
        "        continue\n",
        "    conf = probs[idx].mean()\n",
        "    acc = ((probs[idx] >= chosen).astype(int) == yte[idx]).mean()\n",
        "    ece += idx.mean() * abs(acc - conf)\n",
        "\n",
        "print(f\"ROC-AUC: {auc:.2f}\")\n",
        "print(f\"PPV @ 0.80 sensitivity: {best_ppv:.2f} (threshold ~ {chosen:.2f})\")\n",
        "print(f\"ECE: {ece:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhR8ATBSkjfP",
        "outputId": "0c1c6af2-987a-4779-fb32-e7cda0a1c669"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 1.00\n",
            "PPV @ 0.80 sensitivity: 1.00 (threshold ~ 0.07)\n",
            "ECE: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = files[0]\n",
        "feat = extract_features(test_path).reshape(1, -1)\n",
        "p = cal.predict_proba(feat)[0, 1]\n",
        "print(\"Test file:\", os.path.basename(test_path))\n",
        "print(f\"Estimated risk score: {p:.2f}\")\n",
        "print(\"Not a diagnosis — demo only.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_-ety7jkn_A",
        "outputId": "b536f90f-5d1b-4862-d112-115f71bee49f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test file: imp_0.wav\n",
            "Estimated risk score: 0.98\n",
            "Not a diagnosis — demo only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, sklearn, librosa, numpy\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"librosa:\", librosa.__version__)\n",
        "print(\"numpy:\", numpy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJMZwH23krrd",
        "outputId": "2489492c-16b0-406b-89f3-96956618c152"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "sklearn: 1.6.1\n",
            "librosa: 0.11.0\n",
            "numpy: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File → Save a copy to GitHub  \n",
        "Repo: select my repo  \n",
        "Path: /notebooks/Cognisight_AI_Speech_Analysis.ipynb  \n",
        "Commit: “Add reproducible hackathon notebook”\n"
      ],
      "metadata": {
        "id": "OPXYfrr9kvWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Colab](https://colab.research.google.com/assets/colab-badge.svg)\n"
      ],
      "metadata": {
        "id": "vj6FcC_jk1EL"
      }
    }
  ]
}